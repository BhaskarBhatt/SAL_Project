{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-02T23:08:43.093254Z",
     "iopub.status.busy": "2024-12-02T23:08:43.090171Z",
     "iopub.status.idle": "2024-12-02T23:08:54.944461Z",
     "shell.execute_reply": "2024-12-02T23:08:54.943437Z",
     "shell.execute_reply.started": "2024-12-02T23:08:43.093192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Collecting opensmile\n",
      "  Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.8)\n",
      "Collecting audobject>=0.6.1 (from opensmile)\n",
      "  Downloading audobject-0.7.11-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting audinterface>=0.7.0 (from opensmile)\n",
      "  Downloading audinterface-1.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Collecting audeer>=1.18.0 (from audinterface>=0.7.0->opensmile)\n",
      "  Downloading audeer-2.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
      "  Downloading audformat-1.3.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
      "  Downloading audiofile-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
      "  Downloading audmath-1.4.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
      "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from audobject>=0.6.1->opensmile) (7.0.0)\n",
      "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
      "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from audobject>=0.6.1->opensmile) (21.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (3.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
      "  Downloading iso639_lang-2.5.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
      "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /opt/conda/lib/python3.10/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (16.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.19.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->audobject>=0.6.1->opensmile) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading audinterface-1.2.2-py3-none-any.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audeer-2.2.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audformat-1.3.1-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audiofile-1.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
      "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
      "Downloading iso639_lang-2.5.1-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, audobject, audiofile, audformat, audinterface, opensmile\n",
      "Successfully installed audeer-2.2.0 audformat-1.3.1 audinterface-1.2.2 audiofile-1.5.0 audmath-1.4.1 audobject-0.7.11 audresample-1.3.3 iso3166-2.1.1 iso639-lang-2.5.1 opensmile-2.5.0 oyaml-1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa opensmile soundfile tqdm pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:09:00.217296Z",
     "iopub.status.busy": "2024-12-02T23:09:00.216954Z",
     "iopub.status.idle": "2024-12-02T23:09:00.731555Z",
     "shell.execute_reply": "2024-12-02T23:09:00.730895Z",
     "shell.execute_reply.started": "2024-12-02T23:09:00.217265Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import opensmile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import opensmile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T00:31:58.492461Z",
     "iopub.status.busy": "2024-12-03T00:31:58.492089Z",
     "iopub.status.idle": "2024-12-03T01:08:02.278059Z",
     "shell.execute_reply": "2024-12-03T01:08:02.277002Z",
     "shell.execute_reply.started": "2024-12-03T00:31:58.492430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 55/55 [01:19<00:00,  1.45s/it]\n",
      "100%|██████████| 22/22 [00:31<00:00,  1.43s/it]\n",
      "100%|██████████| 41/41 [00:58<00:00,  1.43s/it]\n",
      "100%|██████████| 45/45 [01:04<00:00,  1.44s/it]\n",
      "100%|██████████| 55/55 [01:18<00:00,  1.42s/it]\n",
      "100%|██████████| 55/55 [01:18<00:00,  1.43s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 55/55 [01:17<00:00,  1.40s/it]\n",
      "100%|██████████| 55/55 [01:18<00:00,  1.42s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 55/55 [03:45<00:00,  4.11s/it]\n",
      "100%|██████████| 22/22 [01:31<00:00,  4.14s/it]\n",
      "100%|██████████| 41/41 [02:44<00:00,  4.00s/it]\n",
      "100%|██████████| 45/45 [02:53<00:00,  3.86s/it]\n",
      "100%|██████████| 55/55 [03:49<00:00,  4.17s/it]\n",
      "100%|██████████| 55/55 [03:38<00:00,  3.97s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 55/55 [02:58<00:00,  3.25s/it]\n",
      "100%|██████████| 55/55 [04:15<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved features to /kaggle/working/Final Dataset/Structural/Structural_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Final Dataset/Structural/Structural_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Kontaktpachydermie/Kontaktpachydermie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Kontaktpachydermie/Kontaktpachydermie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Stimmlippenkarzinom/Stimmlippenkarzinom_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Stimmlippenkarzinom/Stimmlippenkarzinom_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Leukoplakie/Leukoplakie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Leukoplakie/Leukoplakie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Stimmlippenpolyp/Stimmlippenpolyp_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Stimmlippenpolyp/Stimmlippenpolyp_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Laryngitis/Laryngitis_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Laryngitis/Laryngitis_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Reinke Ödem/Reinke Ödem_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Reinke Ödem/Reinke Ödem_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Final Dataset/Neurogenic/Neurogenic_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Final Dataset/Neurogenic/Neurogenic_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Spasmodische Dysphonie/Spasmodische Dysphonie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Spasmodische Dysphonie/Spasmodische Dysphonie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Rekurrensparese/Rekurrensparese_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Continuous Speech/Rekurrensparese/Rekurrensparese_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Kontaktpachydermie/Kontaktpachydermie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Kontaktpachydermie/Kontaktpachydermie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Stimmlippenkarzinom/Stimmlippenkarzinom_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Stimmlippenkarzinom/Stimmlippenkarzinom_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Leukoplakie/Leukoplakie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Leukoplakie/Leukoplakie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Stimmlippenpolyp/Stimmlippenpolyp_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Stimmlippenpolyp/Stimmlippenpolyp_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Laryngitis/Laryngitis_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Laryngitis/Laryngitis_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Reinke Ödem/Reinke Ödem_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Reinke Ödem/Reinke Ödem_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Spasmodische Dysphonie/Spasmodische Dysphonie_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Spasmodische Dysphonie/Spasmodische Dysphonie_lld.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Rekurrensparese/Rekurrensparese_features_all.csv\n",
      "\n",
      "Saved features to /kaggle/working/Sustained Vowels/Rekurrensparese/Rekurrensparese_lld.csv\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import opensmile\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# class VoiceAnalyzer:\n",
    "#     def __init__(self, sample_rate=16000):\n",
    "#         \"\"\"Initialize the voice analyzer with extended feature extraction.\"\"\"\n",
    "#         self.sample_rate = sample_rate\n",
    "#         # Initialize openSMILE feature extractor for comprehensive features\n",
    "#         self.smile_extended = opensmile.Smile(\n",
    "#             feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "#             feature_level=opensmile.FeatureLevel.Functionals,\n",
    "#         )\n",
    "#         # Initialize openSMILE feature extractor for low-level descriptors\n",
    "#         self.smile_lld = opensmile.Smile(\n",
    "#             feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "#             feature_level=opensmile.FeatureLevel.LowLevelDescriptors\n",
    "#         )\n",
    "\n",
    "#     def load_audio(self, file_path):\n",
    "#         \"\"\"Load and preprocess audio file.\"\"\"\n",
    "#         audio, sr = librosa.load(file_path, sr=self.sample_rate)\n",
    "#         return librosa.util.normalize(audio)\n",
    "\n",
    "#     def perform_forced_alignment(self, audio, file_type='phrase'):\n",
    "#         \"\"\"Perform detailed forced alignment based on file type.\"\"\"\n",
    "#         total_duration = len(audio) / self.sample_rate\n",
    "#         if file_type == 'phrase':\n",
    "#             words = ['Guten', 'Morgen', 'wie', 'geht', 'es', 'Ihnen']\n",
    "#             word_proportions = [0.15, 0.2, 0.15, 0.15, 0.15, 0.2]\n",
    "#             alignments = []\n",
    "#             current_time = 0.0\n",
    "#             for word, prop in zip(words, word_proportions):\n",
    "#                 duration = total_duration * prop\n",
    "#                 alignments.append({'word': word, 'start': current_time, 'end': current_time + duration})\n",
    "#                 current_time += duration\n",
    "#         else:\n",
    "#             segment_duration = total_duration / 3\n",
    "#             alignments = [\n",
    "#                 {'vowel': 'i', 'start': 0.0, 'end': segment_duration},\n",
    "#                 {'vowel': 'a', 'start': segment_duration, 'end': 2 * segment_duration},\n",
    "#                 {'vowel': 'u', 'start': 2 * segment_duration, 'end': total_duration}\n",
    "#             ]\n",
    "#         return alignments\n",
    "\n",
    "#     def extract_comprehensive_features(self, audio, alignments):\n",
    "#         \"\"\"Extract comprehensive set of features.\"\"\"\n",
    "#         features = {'full_signal': {}, 'segments': {}}\n",
    "        \n",
    "#         # Full signal features\n",
    "#         full_signal_functionals = self.smile_extended.process_signal(audio, self.sample_rate)\n",
    "#         full_signal_llds = self.smile_lld.process_signal(audio, self.sample_rate)\n",
    "        \n",
    "#         features['full_signal']['functionals'] = full_signal_functionals.values[0]\n",
    "\n",
    "#         # Compute statistics for full signal LLDs\n",
    "#         features['full_signal']['lld_stats'] = {}\n",
    "#         for column in full_signal_llds.columns:\n",
    "#             lld_data = full_signal_llds[column]\n",
    "#             features['full_signal']['lld_stats'][column] = {\n",
    "#                 'mean': np.mean(lld_data),\n",
    "#                 'median': np.median(lld_data),\n",
    "#                 'std': np.std(lld_data),\n",
    "#                 'min': np.min(lld_data),\n",
    "#                 'max': np.max(lld_data),\n",
    "#                 'q1': np.percentile(lld_data, 25),\n",
    "#                 'q3': np.percentile(lld_data, 75),\n",
    "#                 'iqr': np.subtract(*np.percentile(lld_data, [75, 25])),\n",
    "#                 'skewness': np.mean(((lld_data - np.mean(lld_data)) / np.std(lld_data)) ** 3),\n",
    "#                 'kurtosis': np.mean(((lld_data - np.mean(lld_data)) / np.std(lld_data)) ** 4)\n",
    "#             }\n",
    "\n",
    "#         # Segment-wise feature extraction\n",
    "#         for segment in alignments:\n",
    "#             start_sample = int(segment['start'] * self.sample_rate)\n",
    "#             end_sample = int(segment['end'] * self.sample_rate)\n",
    "#             audio_segment = audio[start_sample:end_sample]\n",
    "#             segment_name = segment.get('word', segment.get('vowel', 'unknown'))\n",
    "            \n",
    "#             segment_functionals = self.smile_extended.process_signal(audio_segment, self.sample_rate)\n",
    "#             segment_llds = self.smile_lld.process_signal(audio_segment, self.sample_rate)\n",
    "\n",
    "#             segment_features = {\n",
    "#                 'functionals': segment_functionals.values[0],\n",
    "#                 'lld_stats': {}\n",
    "#             }\n",
    "\n",
    "#             for column in segment_llds.columns:\n",
    "#                 lld_data = segment_llds[column]\n",
    "#                 segment_features['lld_stats'][column] = {\n",
    "#                     'mean': np.mean(lld_data),\n",
    "#                     'median': np.median(lld_data),\n",
    "#                     'std': np.std(lld_data),\n",
    "#                     'min': np.min(lld_data),\n",
    "#                     'max': np.max(lld_data),\n",
    "#                     'q1': np.percentile(lld_data, 25),\n",
    "#                     'q3': np.percentile(lld_data, 75),\n",
    "#                     'iqr': np.subtract(*np.percentile(lld_data, [75, 25])),\n",
    "#                     'skewness': np.mean(((lld_data - np.mean(lld_data)) / np.std(lld_data)) ** 3),\n",
    "#                     'kurtosis': np.mean(((lld_data - np.mean(lld_data)) / np.std(lld_data)) ** 4)\n",
    "#                 }\n",
    "            \n",
    "#             features['segments'][segment_name] = segment_features\n",
    "        \n",
    "#         return features\n",
    "\n",
    "#     def extract_lld_features(self, audio):\n",
    "#         \"\"\"Extract only low-level descriptors (LLD) features.\"\"\"\n",
    "#         lld_features = self.smile_lld.process_signal(audio, self.sample_rate)\n",
    "#         return lld_features\n",
    "\n",
    "#     def process_dataset(self, base_dir, output_base_dir='/kaggle/working'):\n",
    "#         \"\"\"Process datasets located in a hierarchical structure.\"\"\"\n",
    "#         diseases_results_comprehensive = {}\n",
    "#         diseases_results_lld_only = {}\n",
    "\n",
    "#         # Traverse through the directory structure to find all .wav files\n",
    "#         for root, dirs, files in os.walk(base_dir):\n",
    "#             # Skip the base directory and intermediate directories\n",
    "#             if root == base_dir or len(root.split(os.sep)) <= len(base_dir.split(os.sep)) + 1:\n",
    "#                 continue\n",
    "\n",
    "#             # Get the specific disease label (last folder in path)\n",
    "#             label = os.path.basename(root)\n",
    "            \n",
    "#             # Determine speech type (from parent directory)\n",
    "#             speech_type = os.path.basename(os.path.dirname(os.path.dirname(root)))\n",
    "\n",
    "#             if (speech_type, label) not in diseases_results_comprehensive:\n",
    "#                 diseases_results_comprehensive[(speech_type, label)] = []\n",
    "#                 diseases_results_lld_only[(speech_type, label)] = []\n",
    "\n",
    "#             for filename in tqdm(files):\n",
    "#                 if filename.endswith('.wav'):\n",
    "#                     file_path = os.path.join(root, filename)\n",
    "#                     try:\n",
    "#                         audio = self.load_audio(file_path)\n",
    "                        \n",
    "#                         # Determine alignment type based on speech type\n",
    "#                         alignment_type = 'vowel' if speech_type == 'Sustained Vowels' else 'phrase'\n",
    "#                         alignments = self.perform_forced_alignment(audio, file_type=alignment_type)\n",
    "\n",
    "#                         # Extract comprehensive features\n",
    "#                         comprehensive_features = self.extract_comprehensive_features(audio, alignments)\n",
    "#                         diseases_results_comprehensive[(speech_type, label)].append({\n",
    "#                             'filename': filename,\n",
    "#                             'features': comprehensive_features\n",
    "#                         })\n",
    "                        \n",
    "#                         # Extract LLD features only\n",
    "#                         lld_features_only = self.extract_lld_features(audio)\n",
    "#                         diseases_results_lld_only[(speech_type, label)].append({\n",
    "#                             'filename': filename,\n",
    "#                             **{f'lld_{i}': val for i, val in enumerate(lld_features_only.values[0])}\n",
    "#                         })\n",
    "\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error processing {filename}: {str(e)}\")\n",
    "#                         continue\n",
    "        \n",
    "#         # Save results to CSV files for each disease type and speech type\n",
    "#         for (speech_type, disease), results in diseases_results_comprehensive.items():\n",
    "#             # Create nested directories\n",
    "#             output_dir = os.path.join(output_base_dir, speech_type, disease)\n",
    "#             os.makedirs(output_dir, exist_ok=True)            \n",
    "#             # Save comprehensive and LLD features with new naming convention\n",
    "#             comprehensive_output = os.path.join(output_dir, f'{disease}_features_all.csv')\n",
    "#             lld_output = os.path.join(output_dir, f'{disease}_lld.csv')\n",
    "            \n",
    "#             self.save_results(results, comprehensive_output)\n",
    "#             self.save_results(diseases_results_lld_only[(speech_type, disease)], lld_output)\n",
    "\n",
    "#     def save_results(self, results, output_file):\n",
    "#         \"\"\"Save processed results to a CSV file.\"\"\"\n",
    "#         features_data = []\n",
    "        \n",
    "#         for result in results:\n",
    "#             # Handle different types of results\n",
    "#             record = {}\n",
    "            \n",
    "#             # Case 1: Comprehensive features dictionary\n",
    "#             if isinstance(result, dict) and 'features' in result:\n",
    "#                 record['filename'] = result.get('filename', 'unknown')\n",
    "#                 features = result['features']\n",
    "                \n",
    "#                 # Flatten full signal functionals\n",
    "#                 if 'full_signal' in features and 'functionals' in features['full_signal']:\n",
    "#                     for i, func_val in enumerate(features['full_signal']['functionals']):\n",
    "#                         record[f'full_signal_functional_{i}'] = func_val\n",
    "                \n",
    "#                 # Flatten full signal LLD stats\n",
    "#                 if 'full_signal' in features and 'lld_stats' in features['full_signal']:\n",
    "#                     for col, stats in features['full_signal']['lld_stats'].items():\n",
    "#                         for stat_name, stat_val in stats.items():\n",
    "#                             record[f'full_signal_lld_{col}_{stat_name}'] = stat_val\n",
    "            \n",
    "#                 # Flatten segment features\n",
    "#                 if 'segments' in features:\n",
    "#                     for segment_name, segment_data in features['segments'].items():\n",
    "#                         # Segment functionals\n",
    "#                         if 'functionals' in segment_data:\n",
    "#                             for i, func_val in enumerate(segment_data['functionals']):\n",
    "#                                 record[f'{segment_name}_functional_{i}'] = func_val\n",
    "                        \n",
    "#                         # Segment LLD stats\n",
    "#                         if 'lld_stats' in segment_data:\n",
    "#                             for col, stats in segment_data['lld_stats'].items():\n",
    "#                                 for stat_name, stat_val in stats.items():\n",
    "#                                     record[f'{segment_name}_lld_{col}_{stat_name}'] = stat_val\n",
    "            \n",
    "#             # Case 2: LLD-only features (already in a flat format)\n",
    "#             elif isinstance(result, dict):\n",
    "#                 record = result\n",
    "            \n",
    "#             # Case 3: Unexpected format\n",
    "#             else:\n",
    "#                 print(f\"Unexpected result format: {result}\")\n",
    "#                 continue\n",
    "            \n",
    "#             features_data.append(record)\n",
    "    \n",
    "#         # Convert to DataFrame and save\n",
    "#         df = pd.DataFrame(features_data)\n",
    "        \n",
    "#         df.to_csv(output_file, index=False)\n",
    "#         print(f\"\\nSaved features to {output_file}\")\n",
    "    \n",
    "# def main():\n",
    "#     input_base = \"/kaggle/input/all-disease/SAL_Project-main/Final Dataset\"  \n",
    "#     output_base = '/kaggle/working'  # Kaggle output directory\n",
    "    \n",
    "#     analyzer = VoiceAnalyzer()\n",
    "#     analyzer.process_dataset(input_base, output_base)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T20:44:44.793422Z",
     "iopub.status.busy": "2024-12-02T20:44:44.793009Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SVM CODE\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import (\n",
    "#     classification_report,\n",
    "#     confusion_matrix,\n",
    "#     accuracy_score,\n",
    "#     precision_score,\n",
    "#     recall_score,\n",
    "#     f1_score,\n",
    "#     roc_auc_score,\n",
    "#     roc_curve\n",
    "# )\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import joblib\n",
    "\n",
    "# def load_feature_csv(filepath):\n",
    "#     \"\"\"\n",
    "#     Load feature CSV and split into features and labels.\n",
    "\n",
    "#     Args:\n",
    "#         filepath (str): Path to CSV file with features.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Features (X) and labels (y).\n",
    "#     \"\"\"\n",
    "#     df = pd.read_csv(filepath)\n",
    "    \n",
    "#     # Extract features and labels\n",
    "#     X = df.iloc[:, 3:].values  # Features start from the 4th column\n",
    "#     y = df.iloc[:, 1].values   # Labels in the second column\n",
    "    \n",
    "#     # Validate data: Replace NaN or inf values\n",
    "#     X = np.nan_to_num(X, nan=np.nanmean(X, axis=0))  # Replace NaN with column mean\n",
    "#     X = np.where(np.isinf(X), np.nanmax(X, axis=0), X)  # Replace inf with column max\n",
    "    \n",
    "#     return X, y\n",
    "\n",
    "# def train_svm_classifier(X, y, feature_type):\n",
    "#     \"\"\"\n",
    "#     Train SVM classifier with comprehensive analysis.\n",
    "\n",
    "#     Args:\n",
    "#         X (numpy.ndarray): Feature matrix.\n",
    "#         y (numpy.ndarray): Labels.\n",
    "#         feature_type (str): Type of features ('full' or 'lld').\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Comprehensive classification results.\n",
    "#     \"\"\"\n",
    "#     # Encode labels\n",
    "#     le = LabelEncoder()\n",
    "#     y_encoded = le.fit_transform(y)\n",
    "    \n",
    "#     # Split data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y_encoded, test_size=0.2, random_state=42\n",
    "#     )\n",
    "    \n",
    "#     # Scale features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "#     # Validate scaled data\n",
    "#     if np.isnan(X_train_scaled).any() or np.isinf(X_train_scaled).any():\n",
    "#         raise ValueError(\"Training feature matrix contains NaN or infinite values after scaling.\")\n",
    "    \n",
    "#     # Cross-validation\n",
    "#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     # Train SVM\n",
    "#     svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    \n",
    "#     # Cross-validation scores\n",
    "#     cv_scores = cross_val_score(svm, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "    \n",
    "#     # Fit on full training data\n",
    "#     svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     # Predictions\n",
    "#     y_pred = svm.predict(X_test_scaled)\n",
    "#     y_pred_proba = svm.predict_proba(X_test_scaled)\n",
    "    \n",
    "#     # Metrics\n",
    "#     metrics = {\n",
    "#         'Accuracy': accuracy_score(y_test, y_pred),\n",
    "#         'Precision (Macro)': precision_score(y_test, y_pred, average='macro'),\n",
    "#         'Recall (Macro)': recall_score(y_test, y_pred, average='macro'),\n",
    "#         'F1-Score (Macro)': f1_score(y_test, y_pred, average='macro'),\n",
    "#         'ROC AUC': roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "#     }\n",
    "    \n",
    "#     # Visualization: Confusion Matrix\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "#                 xticklabels=le.classes_, \n",
    "#                 yticklabels=le.classes_)\n",
    "#     plt.title(f'Confusion Matrix - {feature_type.upper()} Features')\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'confusion_matrix_{feature_type}_features.png')\n",
    "#     plt.close()\n",
    "    \n",
    "#     # ROC Curve\n",
    "#     fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "#     plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title(f'ROC Curve - {feature_type.upper()} Features')\n",
    "#     plt.savefig(f'roc_curve_{feature_type}_features.png')\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Detailed classification report\n",
    "#     detailed_report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "    \n",
    "#     return {\n",
    "#         'metrics': metrics,\n",
    "#         'cv_scores': {\n",
    "#             'mean': cv_scores.mean(),\n",
    "#             'std': cv_scores.std()\n",
    "#         },\n",
    "#         'detailed_report': detailed_report,\n",
    "#         'model': svm,\n",
    "#         'scaler': scaler,\n",
    "#         'label_encoder': le\n",
    "#     }\n",
    "\n",
    "# def main():\n",
    "#     # Paths to feature CSV files\n",
    "#     full_features_path = '/kaggle/input/features/voice_features_comprehensive.csv'\n",
    "#     lld_features_path = '/kaggle/input/features/voice_features_252_llds.csv'\n",
    "    \n",
    "#     # Analyze features with tqdm\n",
    "#     for feature_type, feature_path in tqdm([(\"full\", full_features_path), (\"lld\", lld_features_path)], desc=\"Feature Set Analysis\"):\n",
    "#         print(f\"\\nAnalyzing {feature_type.upper()} Feature Set\")\n",
    "#         X, y = load_feature_csv(feature_path)\n",
    "#         results = train_svm_classifier(X, y, feature_type)\n",
    "        \n",
    "#         # Print results\n",
    "#         print(f\"\\n{feature_type.upper()} Feature Set Results:\")\n",
    "#         for metric, value in results['metrics'].items():\n",
    "#             print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "#         print(\"\\nCross-Validation:\")\n",
    "#         print(f\"Mean Accuracy: {results['cv_scores']['mean']:.4f}\")\n",
    "#         print(f\"Standard Deviation: {results['cv_scores']['std']:.4f}\")\n",
    "        \n",
    "#         print(\"\\nDetailed Classification Report:\")\n",
    "#         print(results['detailed_report'])\n",
    "        \n",
    "#         # Save model\n",
    "#         joblib.dump({\n",
    "#             'model': results['model'],\n",
    "#             'scaler': results['scaler'],\n",
    "#             'label_encoder': results['label_encoder']\n",
    "#         }, f'{feature_type}_feature_svm.pkl')\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T03:23:37.669984Z",
     "iopub.status.busy": "2024-12-03T03:23:37.669652Z",
     "iopub.status.idle": "2024-12-03T03:25:57.558639Z",
     "shell.execute_reply": "2024-12-03T03:25:57.557744Z",
     "shell.execute_reply.started": "2024-12-03T03:23:37.669954Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Speech Types:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing continuous speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing continuous speech CSVs:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Processing continuous speech CSVs:   6%|▋         | 1/16 [00:01<00:29,  1.96s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  12%|█▎        | 2/16 [00:03<00:21,  1.55s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  25%|██▌       | 4/16 [00:05<00:14,  1.23s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  31%|███▏      | 5/16 [00:07<00:16,  1.47s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  38%|███▊      | 6/16 [00:08<00:15,  1.53s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  44%|████▍     | 7/16 [00:10<00:13,  1.55s/it]\u001b[A\n",
      "Processing continuous speech CSVs:  56%|█████▋    | 9/16 [00:12<00:09,  1.31s/it]\u001b[A\n",
      "Processing continuous speech CSVs: 100%|██████████| 16/16 [00:14<00:00,  1.08it/s]\u001b[A\n",
      "\n",
      "Cross-validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Cross-validation:  20%|██        | 1/5 [00:12<00:49, 12.48s/it]\u001b[A\n",
      "Cross-validation:  40%|████      | 2/5 [00:22<00:33, 11.17s/it]\u001b[A\n",
      "Cross-validation:  60%|██████    | 3/5 [00:32<00:21, 10.69s/it]\u001b[A\n",
      "Cross-validation:  80%|████████  | 4/5 [00:44<00:11, 11.26s/it]\u001b[A\n",
      "Cross-validation: 100%|██████████| 5/5 [00:54<00:00, 10.98s/it]\u001b[A\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "continuous speech Feature + LLD Set Results:\n",
      "Accuracy: 0.3117\n",
      "Precision (Macro): 0.2673\n",
      "Recall (Macro): 0.2917\n",
      "F1-Score (Macro): 0.2284\n",
      "ROC AUC (Macro): 0.7301\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.3107\n",
      "Standard Deviation: 0.0510\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.18      0.83      0.29         6\n",
      "            Laryngitis       0.50      0.13      0.21        15\n",
      "           Leukoplakie       0.00      0.00      0.00         9\n",
      "           Reinke Ödem       0.33      0.20      0.25        10\n",
      "       Rekurrensparese       0.22      0.50      0.30        10\n",
      "Spasmodische Dysphonie       0.91      0.67      0.77        15\n",
      "   Stimmlippenkarzinom       0.00      0.00      0.00         7\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00         5\n",
      "\n",
      "              accuracy                           0.31        77\n",
      "             macro avg       0.27      0.29      0.23        77\n",
      "          weighted avg       0.36      0.31      0.29        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Speech Types:  50%|█████     | 1/2 [01:30<01:30, 90.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing sustained vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sustained vowel CSVs:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:   6%|▋         | 1/16 [00:00<00:13,  1.11it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  12%|█▎        | 2/16 [00:01<00:09,  1.45it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  25%|██▌       | 4/16 [00:02<00:06,  1.75it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  31%|███▏      | 5/16 [00:03<00:07,  1.49it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  38%|███▊      | 6/16 [00:04<00:07,  1.37it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  44%|████▍     | 7/16 [00:05<00:07,  1.26it/s]\u001b[A\n",
      "Processing sustained vowel CSVs:  56%|█████▋    | 9/16 [00:06<00:04,  1.53it/s]\u001b[A\n",
      "Processing sustained vowel CSVs: 100%|██████████| 16/16 [00:07<00:00,  2.23it/s]\u001b[A\n",
      "\n",
      "Cross-validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Cross-validation:  20%|██        | 1/5 [00:05<00:22,  5.53s/it]\u001b[A\n",
      "Cross-validation:  40%|████      | 2/5 [00:11<00:16,  5.64s/it]\u001b[A\n",
      "Cross-validation:  60%|██████    | 3/5 [00:17<00:11,  5.70s/it]\u001b[A\n",
      "Cross-validation:  80%|████████  | 4/5 [00:25<00:06,  6.61s/it]\u001b[A\n",
      "Cross-validation: 100%|██████████| 5/5 [00:30<00:00,  6.17s/it]\u001b[A\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Processing Speech Types: 100%|██████████| 2/2 [02:19<00:00, 69.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sustained vowel Feature + LLD Set Results:\n",
      "Accuracy: 0.3896\n",
      "Precision (Macro): 0.2657\n",
      "Recall (Macro): 0.3542\n",
      "F1-Score (Macro): 0.2906\n",
      "ROC AUC (Macro): 0.7335\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.4116\n",
      "Standard Deviation: 0.0339\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.29      0.83      0.43         6\n",
      "            Laryngitis       0.24      0.27      0.25        15\n",
      "           Leukoplakie       0.00      0.00      0.00         9\n",
      "           Reinke Ödem       0.33      0.50      0.40        10\n",
      "       Rekurrensparese       0.42      0.50      0.45        10\n",
      "Spasmodische Dysphonie       0.85      0.73      0.79        15\n",
      "   Stimmlippenkarzinom       0.00      0.00      0.00         7\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00         5\n",
      "\n",
      "              accuracy                           0.39        77\n",
      "             macro avg       0.27      0.35      0.29        77\n",
      "          weighted avg       0.33      0.39      0.35        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "def load_feature_csvs(base_dir, speech_type):\n",
    "    all_features = []\n",
    "    all_lld = []\n",
    "    all_labels = []\n",
    "\n",
    "    speech_type_path = os.path.join(base_dir, speech_type)\n",
    "    \n",
    "    # Use tqdm to track CSV processing\n",
    "    csv_files = list(os.listdir(speech_type_path))\n",
    "    for filename in tqdm(csv_files, desc=f\"Processing {speech_type} CSVs\"):\n",
    "        if filename.endswith('_features_all.csv'):\n",
    "            filepath = os.path.join(speech_type_path, filename)\n",
    "            \n",
    "            disease_name = filename.replace('_features_all.csv', '')\n",
    "            \n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            features = df.iloc[:, 3:].values\n",
    "            all_features.append(features)\n",
    "            \n",
    "            all_labels.extend([disease_name] * len(features))\n",
    "        \n",
    "        elif filename.endswith('_lld.csv'):\n",
    "            filepath = os.path.join(speech_type_path, filename)\n",
    "            disease_name = filename.replace('_lld.csv', '')\n",
    "            \n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            lld = df.iloc[:, 1:].values\n",
    "            all_lld.append(lld)\n",
    "    \n",
    "    X_features = np.vstack(all_features) if all_features else np.array([])\n",
    "    X_lld = np.vstack(all_lld) if all_lld else np.array([])\n",
    "    y = np.array(all_labels)\n",
    "    \n",
    "    if len(X_features) > 0:\n",
    "        X_features = np.nan_to_num(X_features, nan=np.nanmean(X_features, axis=0))\n",
    "        X_features = np.where(np.isinf(X_features), np.nanmax(X_features, axis=0), X_features)  \n",
    "    \n",
    "    if len(X_lld) > 0:\n",
    "        X_lld = np.nan_to_num(X_lld, nan=np.nanmean(X_lld, axis=0))  \n",
    "        X_lld = np.where(np.isinf(X_lld), np.nanmax(X_lld, axis=0), X_lld)  \n",
    "    \n",
    "    return (X_features, X_lld), y\n",
    "\n",
    "def train_svm_classifier(X_features, X_lld, y, speech_type):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    X = np.hstack((X_features, X_lld))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    \n",
    "    # Add tqdm for cross-validation\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in tqdm(list(cv.split(X_train_scaled, y_train)), desc=\"Cross-validation\"):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        svm_fold = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "        svm_fold.fit(X_train_fold, y_train_fold)\n",
    "        cv_scores.append(svm_fold.score(X_val_fold, y_val_fold))\n",
    "    \n",
    "    cv_scores = np.array(cv_scores)\n",
    "    \n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    y_pred_proba = svm.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Multiclass ROC AUC handling\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision (Macro)': precision_score(y_test, y_pred, average='macro'),\n",
    "        'Recall (Macro)': recall_score(y_test, y_pred, average='macro'),\n",
    "        'F1-Score (Macro)': f1_score(y_test, y_pred, average='macro'),\n",
    "    }\n",
    "    \n",
    "    # Multiclass ROC AUC using one-vs-rest strategy\n",
    "    try:\n",
    "        metrics['ROC AUC (Macro)'] = roc_auc_score(\n",
    "            y_test, \n",
    "            y_pred_proba, \n",
    "            multi_class='ovr', \n",
    "            average='macro'\n",
    "        )\n",
    "    except ValueError:\n",
    "        metrics['ROC AUC (Macro)'] = None\n",
    "        print(\"Warning: Could not calculate ROC AUC for this dataset\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, \n",
    "                yticklabels=le.classes_,\n",
    "                square=True)\n",
    "    plt.title(f'Confusion Matrix - {speech_type} Features + LLD')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/kaggle/working/confusion_matrix_{speech_type.replace(\" \", \"_\")}_features_lld.png')\n",
    "    plt.close()\n",
    "    \n",
    "    detailed_report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'cv_scores': {\n",
    "            'mean': cv_scores.mean(),\n",
    "            'std': cv_scores.std()\n",
    "        },\n",
    "        'detailed_report': detailed_report,\n",
    "        'model': svm,\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': le\n",
    "    }\n",
    "    \n",
    "def main():\n",
    "    base_dir = '/kaggle/input/all-feat/data'  \n",
    "    \n",
    "    # Speech types to analyze\n",
    "    speech_types = ['continuous speech', 'sustained vowel']\n",
    "    \n",
    "    # Analyze each speech type\n",
    "    for speech_type in tqdm(speech_types, desc=\"Processing Speech Types\"):\n",
    "        print(f\"\\nAnalyzing {speech_type}\")\n",
    "        \n",
    "        # Load features and LLD\n",
    "        (X_features, X_lld), y = load_feature_csvs(base_dir, speech_type)\n",
    "        \n",
    "        # Skip if no data found\n",
    "        if len(X_features) == 0 and len(X_lld) == 0:\n",
    "            print(f\"Skipping {speech_type} - No data found\")\n",
    "            continue\n",
    "        \n",
    "        # Train SVM and get results\n",
    "        results = train_svm_classifier(X_features, X_lld, y, speech_type)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{speech_type} Feature + LLD Set Results:\")\n",
    "        for metric, value in results['metrics'].items():\n",
    "            print(f\"{metric}: {value:.4f}\" if value is not None else f\"{metric}: N/A\")\n",
    "        \n",
    "        print(\"\\nCross-Validation:\")\n",
    "        print(f\"Mean Accuracy: {results['cv_scores']['mean']:.4f}\")\n",
    "        print(f\"Standard Deviation: {results['cv_scores']['std']:.4f}\")\n",
    "        \n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(results['detailed_report'])\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump({\n",
    "            'model': results['model'],\n",
    "            'scaler': results['scaler'],\n",
    "            'label_encoder': results['label_encoder']\n",
    "        }, f'/kaggle/working/{speech_type.replace(\" \", \"_\")}_features_lld_svm_model.pkl')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T03:30:00.287944Z",
     "iopub.status.busy": "2024-12-03T03:30:00.287637Z",
     "iopub.status.idle": "2024-12-03T03:32:21.178997Z",
     "shell.execute_reply": "2024-12-03T03:32:21.178126Z",
     "shell.execute_reply.started": "2024-12-03T03:30:00.287918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing continuous speech - FEATURES Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing continuous speech features CSVs: 100%|██████████| 16/16 [00:14<00:00,  1.09it/s]\n",
      "Cross-validation: 100%|██████████| 5/5 [00:57<00:00, 11.43s/it]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "continuous speech FEATURES Feature Set Results:\n",
      "Accuracy: 0.3117\n",
      "Precision (Macro): 0.2673\n",
      "Recall (Macro): 0.2917\n",
      "F1-Score (Macro): 0.2284\n",
      "ROC AUC (Macro): 0.7296\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.3107\n",
      "Standard Deviation: 0.0510\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.18      0.83      0.29         6\n",
      "            Laryngitis       0.50      0.13      0.21        15\n",
      "           Leukoplakie       0.00      0.00      0.00         9\n",
      "           Reinke Ödem       0.33      0.20      0.25        10\n",
      "       Rekurrensparese       0.22      0.50      0.30        10\n",
      "Spasmodische Dysphonie       0.91      0.67      0.77        15\n",
      "   Stimmlippenkarzinom       0.00      0.00      0.00         7\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00         5\n",
      "\n",
      "              accuracy                           0.31        77\n",
      "             macro avg       0.27      0.29      0.23        77\n",
      "          weighted avg       0.36      0.31      0.29        77\n",
      "\n",
      "\n",
      "Analyzing continuous speech - LLD Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing continuous speech lld CSVs: 100%|██████████| 16/16 [00:00<00:00, 570.58it/s]\n",
      "Cross-validation: 100%|██████████| 5/5 [00:00<00:00, 23.77it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "continuous speech LLD Feature Set Results:\n",
      "Accuracy: 0.1429\n",
      "Precision (Macro): 0.1054\n",
      "Recall (Macro): 0.1437\n",
      "F1-Score (Macro): 0.0952\n",
      "ROC AUC (Macro): 0.4938\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.1829\n",
      "Standard Deviation: 0.0233\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.13      0.44      0.20         9\n",
      "            Laryngitis       0.23      0.20      0.21        15\n",
      "           Leukoplakie       0.00      0.00      0.00         3\n",
      "           Reinke Ödem       0.33      0.08      0.12        13\n",
      "       Rekurrensparese       0.15      0.43      0.22         7\n",
      "Spasmodische Dysphonie       0.00      0.00      0.00        15\n",
      "   Stimmlippenkarzinom       0.00      0.00      0.00         5\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00        10\n",
      "\n",
      "              accuracy                           0.14        77\n",
      "             macro avg       0.11      0.14      0.10        77\n",
      "          weighted avg       0.13      0.14      0.11        77\n",
      "\n",
      "\n",
      "Analyzing sustained vowel - FEATURES Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sustained vowel features CSVs: 100%|██████████| 16/16 [00:06<00:00,  2.66it/s]\n",
      "Cross-validation: 100%|██████████| 5/5 [00:29<00:00,  5.85s/it]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sustained vowel FEATURES Feature Set Results:\n",
      "Accuracy: 0.3766\n",
      "Precision (Macro): 0.2577\n",
      "Recall (Macro): 0.3458\n",
      "F1-Score (Macro): 0.2813\n",
      "ROC AUC (Macro): 0.7340\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.4116\n",
      "Standard Deviation: 0.0339\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.28      0.83      0.42         6\n",
      "            Laryngitis       0.19      0.20      0.19        15\n",
      "           Leukoplakie       0.00      0.00      0.00         9\n",
      "           Reinke Ödem       0.33      0.50      0.40        10\n",
      "       Rekurrensparese       0.42      0.50      0.45        10\n",
      "Spasmodische Dysphonie       0.85      0.73      0.79        15\n",
      "   Stimmlippenkarzinom       0.00      0.00      0.00         7\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00         5\n",
      "\n",
      "              accuracy                           0.38        77\n",
      "             macro avg       0.26      0.35      0.28        77\n",
      "          weighted avg       0.32      0.38      0.33        77\n",
      "\n",
      "\n",
      "Analyzing sustained vowel - LLD Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sustained vowel lld CSVs: 100%|██████████| 16/16 [00:00<00:00, 668.06it/s]\n",
      "Cross-validation: 100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sustained vowel LLD Feature Set Results:\n",
      "Accuracy: 0.3506\n",
      "Precision (Macro): 0.3715\n",
      "Recall (Macro): 0.3237\n",
      "F1-Score (Macro): 0.2834\n",
      "ROC AUC (Macro): 0.7682\n",
      "\n",
      "Cross-Validation:\n",
      "Mean Accuracy: 0.3169\n",
      "Standard Deviation: 0.0441\n",
      "\n",
      "Detailed Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "    Kontaktpachydermie       0.33      0.89      0.48         9\n",
      "            Laryngitis       0.33      0.13      0.19        15\n",
      "           Leukoplakie       0.00      0.00      0.00         3\n",
      "           Reinke Ödem       0.54      0.54      0.54        13\n",
      "       Rekurrensparese       0.17      0.43      0.24         7\n",
      "Spasmodische Dysphonie       0.60      0.40      0.48        15\n",
      "   Stimmlippenkarzinom       1.00      0.20      0.33         5\n",
      "      Stimmlippenpolyp       0.00      0.00      0.00        10\n",
      "\n",
      "              accuracy                           0.35        77\n",
      "             macro avg       0.37      0.32      0.28        77\n",
      "          weighted avg       0.39      0.35      0.32        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "def load_feature_csvs(base_dir, speech_type, feature_type):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    speech_type_path = os.path.join(base_dir, speech_type)\n",
    "    \n",
    "    # Use tqdm to track CSV processing\n",
    "    csv_files = list(os.listdir(speech_type_path))\n",
    "    for filename in tqdm(csv_files, desc=f\"Processing {speech_type} {feature_type} CSVs\"):\n",
    "        if feature_type == 'features' and filename.endswith('_features_all.csv'):\n",
    "            filepath = os.path.join(speech_type_path, filename)\n",
    "            \n",
    "            disease_name = filename.replace('_features_all.csv', '')\n",
    "            \n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            features = df.iloc[:, 3:].values\n",
    "            all_features.append(features)\n",
    "            \n",
    "            all_labels.extend([disease_name] * len(features))\n",
    "        \n",
    "        elif feature_type == 'lld' and filename.endswith('_lld.csv'):\n",
    "            filepath = os.path.join(speech_type_path, filename)\n",
    "            disease_name = filename.replace('_lld.csv', '')\n",
    "            \n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            features = df.iloc[:, 1:].values\n",
    "            all_features.append(features)\n",
    "            \n",
    "            all_labels.extend([disease_name] * len(features))\n",
    "    \n",
    "    X = np.vstack(all_features) if all_features else np.array([])\n",
    "    y = np.array(all_labels)\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        X = np.nan_to_num(X, nan=np.nanmean(X, axis=0))\n",
    "        X = np.where(np.isinf(X), np.nanmax(X, axis=0), X)  \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_svm_classifier(X, y, speech_type, feature_type):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    \n",
    "    # Add tqdm for cross-validation\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in tqdm(list(cv.split(X_train_scaled, y_train)), desc=\"Cross-validation\"):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        svm_fold = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "        svm_fold.fit(X_train_fold, y_train_fold)\n",
    "        cv_scores.append(svm_fold.score(X_val_fold, y_val_fold))\n",
    "    \n",
    "    cv_scores = np.array(cv_scores)\n",
    "    \n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    y_pred_proba = svm.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision (Macro)': precision_score(y_test, y_pred, average='macro'),\n",
    "        'Recall (Macro)': recall_score(y_test, y_pred, average='macro'),\n",
    "        'F1-Score (Macro)': f1_score(y_test, y_pred, average='macro'),\n",
    "    }\n",
    "    \n",
    "    # Multiclass ROC AUC using one-vs-rest strategy\n",
    "    try:\n",
    "        metrics['ROC AUC (Macro)'] = roc_auc_score(\n",
    "            y_test, \n",
    "            y_pred_proba, \n",
    "            multi_class='ovr', \n",
    "            average='macro'\n",
    "        )\n",
    "    except ValueError:\n",
    "        metrics['ROC AUC (Macro)'] = None\n",
    "        print(\"Warning: Could not calculate ROC AUC for this dataset\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, \n",
    "                yticklabels=le.classes_,\n",
    "                square=True)\n",
    "    plt.title(f'Confusion Matrix - {speech_type} {feature_type.upper()} Features')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/kaggle/working/confusion_matrix_{speech_type.replace(\" \", \"_\")}_{feature_type}_features.png')\n",
    "    plt.close()\n",
    "    \n",
    "    detailed_report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'cv_scores': {\n",
    "            'mean': cv_scores.mean(),\n",
    "            'std': cv_scores.std()\n",
    "        },\n",
    "        'detailed_report': detailed_report,\n",
    "        'model': svm,\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': le\n",
    "    }\n",
    "    \n",
    "def main():\n",
    "    base_dir = '/kaggle/input/all-feat/data'  \n",
    "    \n",
    "    # Specific analysis configurations\n",
    "    analysis_configs = [\n",
    "        ('continuous speech', 'features'),\n",
    "        ('continuous speech', 'lld'),\n",
    "        ('sustained vowel', 'features'),\n",
    "        ('sustained vowel', 'lld')\n",
    "    ]\n",
    "    \n",
    "    # Analyze each configuration\n",
    "    for speech_type, feature_type in analysis_configs:\n",
    "        print(f\"\\nAnalyzing {speech_type} - {feature_type.upper()} Features\")\n",
    "        \n",
    "        # Load features\n",
    "        X, y = load_feature_csvs(base_dir, speech_type, feature_type)\n",
    "        \n",
    "        # Skip if no data found\n",
    "        if len(X) == 0:\n",
    "            print(f\"Skipping {speech_type} {feature_type} - No data found\")\n",
    "            continue\n",
    "        \n",
    "        # Train SVM and get results\n",
    "        results = train_svm_classifier(X, y, speech_type, feature_type)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{speech_type} {feature_type.upper()} Feature Set Results:\")\n",
    "        for metric, value in results['metrics'].items():\n",
    "            print(f\"{metric}: {value:.4f}\" if value is not None else f\"{metric}: N/A\")\n",
    "        \n",
    "        print(\"\\nCross-Validation:\")\n",
    "        print(f\"Mean Accuracy: {results['cv_scores']['mean']:.4f}\")\n",
    "        print(f\"Standard Deviation: {results['cv_scores']['std']:.4f}\")\n",
    "        \n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(results['detailed_report'])\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump({\n",
    "            'model': results['model'],\n",
    "            'scaler': results['scaler'],\n",
    "            'label_encoder': results['label_encoder']\n",
    "        }, f'/kaggle/working/{speech_type.replace(\" \", \"_\")}_{feature_type}_svm_model.pkl')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6215528,
     "sourceId": 10081857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6216535,
     "sourceId": 10083343,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
